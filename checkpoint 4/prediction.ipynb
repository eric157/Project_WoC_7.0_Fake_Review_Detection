{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from autocorrect import Speller\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Get the absolute path of the directory containing the current notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add checkpoint 3 for scraped data\n",
    "checkpoint3_dir = os.path.abspath(os.path.join(current_dir, '..', 'checkpoint 3'))\n",
    "sys.path.append(checkpoint3_dir)\n",
    "\n",
    "\n",
    "MODEL_DIR = os.path.join(\"..\",\"checkpoint 2\",\"models\")\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"logistic_regression_model.pkl\")\n",
    "\n",
    "SCRAPED_REVIEWS_PATH = os.path.join(checkpoint3_dir, \"scraped_reviews.csv\")\n",
    "# Define the path for feature names.\n",
    "FEATURE_NAMES_PATH = os.path.join(\"..\",\"checkpoint 1\",\"models\",\"tfidf_feature_names.pkl\")\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "DetectorFactory.seed = 0\n",
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text(separator=' ')\n",
    "\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|\\S+@\\S+|\\#\\S+', '', text, flags=re.MULTILINE)\n",
    "   \n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    tokens = [spell(word) for word in tokens]\n",
    "\n",
    "    tokens = [word.encode('ascii', 'ignore').decode('ascii') for word in tokens]\n",
    "\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_new_text(text, rating):\n",
    "    \"\"\"Preprocesses new text and rating using a trained vectorizer.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(FEATURE_NAMES_PATH):\n",
    "        raise FileNotFoundError(f\"Feature Names not found: {FEATURE_NAMES_PATH}. Please train vectorizer first\")\n",
    "    \n",
    "    if not os.path.exists(os.path.join(\"..\",\"checkpoint 1\",\"models\",\"tfidf_vectorizer.pkl\")):\n",
    "       raise FileNotFoundError(f\"Vectorizer not found: {os.path.join('..','checkpoint 1','models','tfidf_vectorizer.pkl')}. Please train vectorizer first\")\n",
    "    \n",
    "    vectorizer = joblib.load(os.path.join(\"..\",\"checkpoint 1\",\"models\",\"tfidf_vectorizer.pkl\"))\n",
    "    feature_names = joblib.load(FEATURE_NAMES_PATH)\n",
    "\n",
    "    try:\n",
    "        if detect(text) != 'en':\n",
    "            return pd.DataFrame(columns=feature_names.tolist() + ['rating'])\n",
    "    except:\n",
    "         return pd.DataFrame(columns=feature_names.tolist() + ['rating'])\n",
    "\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    tfidf_matrix = vectorizer.transform([preprocessed_text])\n",
    "    tfidf_features = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    tfidf_features['rating'] = float(rating)\n",
    "    \n",
    "    tfidf_features = tfidf_features.reindex(columns = feature_names.tolist() + ['rating'], fill_value=0)\n",
    "    return tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "   if not os.path.exists(MODEL_PATH):\n",
    "      raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}. Please train model first.\")\n",
    "   return joblib.load(MODEL_PATH)\n",
    "model = load_model()\n",
    "scraped_data = pd.read_csv(SCRAPED_REVIEWS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fake_review(row):\n",
    "    \"\"\"\n",
    "    Predicts whether a given text review is fake or not, using preprocessed text and rating.\n",
    "\n",
    "    Args:\n",
    "       row(pd.Series): Row from the scraped data.\n",
    "    Returns:\n",
    "        int: Predicted label (0 for not fake, 1 for fake)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = row['text']\n",
    "        rating = row['rating']\n",
    "        preprocessed_features = preprocess_new_text(text, rating)\n",
    "        prediction = model.predict(preprocessed_features)[0]\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericp\\AppData\\Local\\Temp\\ipykernel_14016\\2111625023.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n",
      "C:\\Users\\ericp\\AppData\\Local\\Temp\\ipykernel_14016\\2111625023.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: object of type 'float' has no len()\n",
      "Predictions applied.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Apple iPhone XR is an excellent device wit...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battery good durability, all functions good, l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The reconditioned iPhone XR was in excellent c...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had this product for a few years and it...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My fiancée ordered this and has been using it ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Nice phone for a good price, works like new</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bueno</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>this phone works great for it for my brother, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I got it for a present and it works great!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The phone works great freeze resistant love th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  rating  predicted_label\n",
       "0   The Apple iPhone XR is an excellent device wit...     5.0              1.0\n",
       "1   Battery good durability, all functions good, l...     5.0              1.0\n",
       "2   The reconditioned iPhone XR was in excellent c...     5.0              1.0\n",
       "3   I have had this product for a few years and it...     4.0              1.0\n",
       "4   My fiancée ordered this and has been using it ...     5.0              1.0\n",
       "..                                                ...     ...              ...\n",
       "95        Nice phone for a good price, works like new     4.0              1.0\n",
       "96                                              Bueno     4.0              1.0\n",
       "97  this phone works great for it for my brother, ...     4.0              1.0\n",
       "98         I got it for a present and it works great!     4.0              1.0\n",
       "99  The phone works great freeze resistant love th...     5.0              1.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_data['predicted_label'] = scraped_data.apply(predict_fake_review, axis=1)\n",
    "\n",
    "print(\"Predictions applied.\")\n",
    "\n",
    "scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_data['predicted_label'].isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_label\n",
       "1.0    92\n",
       "0.0     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_data['predicted_label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
